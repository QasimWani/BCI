{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fft, arange, signal\n",
    "from scipy.special import logit, expit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from ttictoc import TicToc\n",
    "#----------------------\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "#---------------------RF HP-f(x) & CV---------------\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_root_Hypothesis_1 = \"../../Music/hypothesis_1/\"\n",
    "folder_root_Hypothesis_2 = \"../../Music/hypothesis_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    Reads the audio .wav file and returns the sample rate and data contents of the file.\n",
    "    \"\"\"\n",
    "    sr, signal = wavfile.read(path)\n",
    "    return sr, signal[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all(files):\n",
    "    \"\"\"Branch audio file extrapolation. Uses read_file() method.\"\"\"\n",
    "    ret = []\n",
    "    t = TicToc()\n",
    "    t.tic();\n",
    "    for fl in files:\n",
    "        ret.append(read_file(fl))\n",
    "    t.toc();\n",
    "    print(\"Time it took to read data from files of length \", len(files), \" = \", round(t.elapsed, 3), \" seconds.\")\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(PATH, ext):\n",
    "    \"\"\"\n",
    "    Finds all the files in a particular directory. Return only .csv files.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for r, d, f in os.walk(PATH):\n",
    "        for file in f:\n",
    "            if ext in file:\n",
    "                files.append(os.path.join(r, file).replace(\"\\\\\",\"/\"))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files = find_files(folder_root_Hypothesis_1, \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to read data from files of length  13  =  3.025  seconds.\n"
     ]
    }
   ],
   "source": [
    "data = read_all(music_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_sepectrum(sf, x):\n",
    "    \"\"\"\n",
    "    Convertion of Audio from time domain to frequency domain using Fast Fourier Algorithm.\n",
    "    Parameters:\n",
    "    1. sf : sampling frequency (usually 44.1 KHz)\n",
    "    2. x : time domain signals.\n",
    "    Returns:\n",
    "    1. Sampling rate.\n",
    "    2. Frequency distribution (Nyquist maintained)\n",
    "    \"\"\"\n",
    "    x = x - np.average(x)  # zero-centered.\n",
    "\n",
    "    n = len(x)\n",
    "    k = arange(n)\n",
    "    tarr = n / float(sf)\n",
    "    frqarr = k / float(tarr)  # two sides frequency range\n",
    "\n",
    "    frqarr = frqarr[range(n // 2)]  # one side frequency range\n",
    "\n",
    "    x = fft(x) / n  # fft computing and normalization\n",
    "    x = x[range(n // 2)]\n",
    "\n",
    "    return frqarr, abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(sample_rate, signal, state=False):\n",
    "    \"\"\"\n",
    "    Method responsible for converting from time domain to frequency\n",
    "    via the discrete fourier analysis function created in frequency_sepectrum().\n",
    "    Option to form a plot of the resultant frequency domain graph with its frequency content distribution.\n",
    "    Returns:\n",
    "    1. Y: The frequencies.\n",
    "    2. frq: The content distribution.\n",
    "    \"\"\"\n",
    "    frq, Y = frequency_sepectrum(sample_rate, signal)\n",
    "    frq = frq\n",
    "    if(state == True):\n",
    "        plt.plot(frq, Y)\n",
    "        plt.title(\"Frequency (Hz) vs. Magnitude\")\n",
    "        plt.xlabel(\"Frequency (Hz)\")\n",
    "        plt.ylabel(\"Magnitude\")\n",
    "    return Y, frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_0, frequencies_0 = plot(data[-2][0],data[-2][1], True) #Specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = signal.spectrogram(data[0][1], fs=data[0][0]) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, t1, Sxx1 = signal.spectrogram(data[-4][1], fs=data[-4][0]) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(top=1000)\n",
    "plt.xlim(right=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape, f.shape, Sxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum, freq, time, _ = plt.specgram(data[5][1],Fs=data[5][0])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Discrete Foureir Transformation of EEG Data on Same Music files to check for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data = \"../../data/Music/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_music_files = find_files(folder_data, \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meta_data(PATH):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    1. Changes in Electric potential based on Unix timestamp from\n",
    "        the 5 channels of the Emotiv headset. 2 channels from the Frontal Lobe, \n",
    "        1 channel from the parietal lobe, and 2 from temporal lobe.\n",
    "    2. Pandas Dataframe of the data reflected from (1).\n",
    "    \"\"\"\n",
    "    reader = csv.reader(open(PATH, \"rt\"), delimiter='\\t')\n",
    "    i = 0\n",
    "    one_file_data = []\n",
    "    for line in reader:\n",
    "        if(i > 0):\n",
    "            one_file_data.append(line)\n",
    "        i += 1\n",
    "    one_file_data = np.array(one_file_data)\n",
    "    columns = one_file_data[0][0].split(\",\")[3:8]\n",
    "    row_data = []\n",
    "    for rows in one_file_data[1:]:\n",
    "        dtx = rows[0].split(\",\")[3:8]\n",
    "        cont = []\n",
    "        for x in dtx:\n",
    "            cont.append(float(x))\n",
    "        row_data.append(cont)\n",
    "    dataframe = pd.DataFrame(row_data, columns=columns)\n",
    "    return np.array(row_data), dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_DF_dir(list_PATH):\n",
    "    \"\"\"\n",
    "    Returns all the data from a given set of path files and its associated pandas dataframe object.\n",
    "    \"\"\"\n",
    "    raw_data = []\n",
    "    dataframes = []\n",
    "    for file in list_PATH:\n",
    "        rd, dfob = remove_meta_data(file)\n",
    "        raw_data.append(rd)\n",
    "        dataframes.append(dfob)\n",
    "    return raw_data, dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data, brain_df = data_DF_dir(brain_music_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(brain_data[1].T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_music_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_spectrum, EEG_freq, EEG_time, _ = plt.specgram(brain_data[3].T[0],Fs=128)\n",
    "plt.ylim(top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_music_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGf, EEGt, EEGSxx2 = signal.spectrogram(brain_data[-1].T[3], fs=128) #Spectogram\n",
    "plt.pcolormesh(EEGt, EEGf, EEGSxx2)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(top=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarity(a,b):\n",
    "    \"\"\"\n",
    "    Finds the similarity between EEG data file #1 vs. EEG data file #2.\n",
    "    \"\"\"\n",
    "    for i in range(len(a)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_calculator(A, B):\n",
    "    \"\"\"\n",
    "    Finds the distribution from SAMPLE based on TEST data.\n",
    "    Uses jacard similarity.\n",
    "    \"\"\"\n",
    "    intersection = 0\n",
    "    union = 0\n",
    "    for a,b in zip(A,B):\n",
    "        if(bool_similarity_threshold_set(a,b)):\n",
    "            intersection += 1\n",
    "    union = abs(len(A) + len(B) - intersection)\n",
    "    percent = intersection/float(union)\n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 100\n",
    "b = 99\n",
    "c = (a-b)**2\n",
    "d = (a*b)/c\n",
    "d*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sxx.mean(), Sxx1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_music_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGf, EEGt, EEGSxx1 = signal.spectrogram(brain_data[0].T[0], fs=128) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGf, EEGt, EEGSxx2 = signal.spectrogram(brain_data[1].T[0], fs=128) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clench_f, clench_t, clench_Sxx = signal.spectrogram(brain_data[3].T[0], fs=128) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(clench_t, clench_f, clench_Sxx)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toge = list(clench_Sxx[0])\n",
    "for x in range(1, clench_Sxx.shape[0]):\n",
    "    toge.extend(list(clench_Sxx[x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(toge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_music_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGSxx1.mean(), EEGSxx2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS = 1\n",
    "def bool_similarity_threshold_set(A, B):\n",
    "    \"\"\"\n",
    "    bool function to detect for any intersection between two areas of two circles with centers @ A, B.\n",
    "    \"\"\"\n",
    "    return bool(abs(A-B) < RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = 0\n",
    "for i in range(EEGSxx1.shape[0]):\n",
    "    pct += percent_calculator(EEGSxx1[i], EEGSxx2[i])\n",
    "pct /= Sxx.shape[0]\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# music_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGf, EEGt, Sxx1 = signal.spectrogram(data[-4][1], fs=data[0][0]) #Spectogram\n",
    "EEGf, EEGt, Sxx2 = signal.spectrogram(data[-6][1], fs=data[0][0]) #Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = 0\n",
    "for i in range(Sxx1.shape[0]):\n",
    "    pct += percent_calculator(Sxx1[i], Sxx2[i])\n",
    "pct /= Sxx.shape[0]\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude, frequencies = plot(128, brain_data[3].T[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
