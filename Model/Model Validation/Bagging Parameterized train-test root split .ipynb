{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation of hyper-parameter tuned random forest CV algorithm\n",
    "### for one.vs.one classifier.\n",
    "#--> Deals with splitting of training data from source..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "#---------------------RF HP-f(x) & CV---------------\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_root = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(PATH):\n",
    "    \"\"\"\n",
    "    Finds all the files in a particular directory. Return only .csv files.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for r, d, f in os.walk(PATH):\n",
    "        for file in f:\n",
    "            if '.csv' in file:\n",
    "                files.append(os.path.join(r, file).replace(\"\\\\\",\"/\"))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir_files(root):\n",
    "    \"\"\"\n",
    "    Finds all the files in a nested directory of folders and files (.csv)\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    friendly_name = []\n",
    "    for x in os.listdir(root):\n",
    "        subfolder = root + x\n",
    "        if os.path.isdir(subfolder):\n",
    "            onfo = find_files(subfolder)\n",
    "            if(len(onfo) > 0 and len(x.split(\"_\")) > 1):##Removes test folder and empty folders\n",
    "                files.append(onfo)\n",
    "                fn = x.split(\"/\")[-1]\n",
    "                friendly_name.append(fn)\n",
    "    return files, friendly_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files, friendly_name = list_dir_files(folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meta_data(PATH):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    1. Changes in Electric potential based on Unix timestamp from\n",
    "        the 5 channels of the Emotiv headset. 2 channels from the Frontal Lobe, \n",
    "        1 channel from the parietal lobe, and 2 from temporal lobe.\n",
    "    2. Pandas Dataframe of the data reflected from (1).\n",
    "    \"\"\"\n",
    "    reader = csv.reader(open(PATH, \"rt\"), delimiter='\\t')\n",
    "    i = 0\n",
    "    one_file_data = []\n",
    "    for line in reader:\n",
    "        if(i > 0):\n",
    "            one_file_data.append(line)\n",
    "        i += 1\n",
    "    one_file_data = np.array(one_file_data)\n",
    "    columns = one_file_data[0][0].split(\",\")[3:8]\n",
    "    row_data = []\n",
    "    for rows in one_file_data[1:]:\n",
    "        rd = rows[0].split(\",\")[3:8]\n",
    "        rdt = []\n",
    "        for x in rd:\n",
    "            rdt.append(float(x))\n",
    "        row_data.append(rdt)\n",
    "    dataframe = pd.DataFrame(row_data, columns=columns)\n",
    "    return np.array(row_data), dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_DF_dir(list_PATH):\n",
    "    \"\"\"\n",
    "    Returns all the data from a given set of path files and its associated pandas dataframe object.\n",
    "    \"\"\"\n",
    "    raw_data = []\n",
    "    dataframes = []\n",
    "    for file in list_PATH:\n",
    "        rd, dfob = remove_meta_data(file)\n",
    "        raw_data.append(rd)\n",
    "        dataframes.append(dfob)\n",
    "    return np.array(raw_data), dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_subfolder_file_data(root_list):\n",
    "    \"\"\"\n",
    "    Extracts dataframe and np.array() of each file within each subfolder of the root folder.\n",
    "    Returns:\n",
    "    1. n(n will increase)x5(m varies) dataframe\n",
    "    2. n(n will increase)x5(m varies) np.array()\n",
    "    \"\"\"\n",
    "    root_df = []\n",
    "    root_np = []\n",
    "    for x in root_list:\n",
    "        rnd, rdf = data_DF_dir(x)\n",
    "        root_df.append(rdf)\n",
    "        root_np.append(rnd)\n",
    "    return np.array(root_np), root_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, raw_df = root_subfolder_file_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_split(dataframes, friendly_name, merge_name):\n",
    "    \"\"\"\n",
    "    Splits dataframe into training and testing sets based on 80% rule from the directory.\n",
    "    Returns:\n",
    "    1. train_df : set of dataframes used for training. Can be used into training and testing split.\n",
    "    2. test_df  : reserved for testing only.\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    i_train = 0\n",
    "    flag = 0\n",
    "    \n",
    "    for x,fn in zip(dataframes, friendly_name):\n",
    "        i_train = len(x)\n",
    "        for dt in x:\n",
    "            holder = np.full((1, dt.shape[0]), float(fn.split(\"_\")[0])).T\n",
    "            temp_df = dt\n",
    "            temp_df[merge_name] = holder\n",
    "            if(flag < i_train -1):\n",
    "                train.append(temp_df)\n",
    "            else:\n",
    "                test.append(temp_df)\n",
    "            flag += 1\n",
    "        flag = 0\n",
    "            \n",
    "    train_df = train[0]\n",
    "    test_df = test[0]\n",
    "    \n",
    "    for i in range(1, len(train)):\n",
    "        train_df = train_df.append(train[i])\n",
    "    train_df = train_df.reset_index().drop(['index'],axis=1) \n",
    "    \n",
    "    for i in range(1, len(test)):\n",
    "        test_df = test_df.append(test[i])\n",
    "    test_df = test_df.reset_index().drop(['index'],axis=1) \n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = merge_split(raw_df, friendly_name, \"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31899.000000</td>\n",
       "      <td>31899.000000</td>\n",
       "      <td>31899.000000</td>\n",
       "      <td>31899.000000</td>\n",
       "      <td>31899.000000</td>\n",
       "      <td>31899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4225.962946</td>\n",
       "      <td>4339.589441</td>\n",
       "      <td>4150.735775</td>\n",
       "      <td>4136.736518</td>\n",
       "      <td>4195.568329</td>\n",
       "      <td>3.421424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.116010</td>\n",
       "      <td>148.580112</td>\n",
       "      <td>127.110545</td>\n",
       "      <td>126.976150</td>\n",
       "      <td>172.321026</td>\n",
       "      <td>2.454666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3445.128174</td>\n",
       "      <td>2828.718018</td>\n",
       "      <td>2342.564209</td>\n",
       "      <td>3364.102539</td>\n",
       "      <td>1709.230713</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4190.256348</td>\n",
       "      <td>4266.153809</td>\n",
       "      <td>4116.410156</td>\n",
       "      <td>4108.205078</td>\n",
       "      <td>4170.256348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4225.641113</td>\n",
       "      <td>4340.000000</td>\n",
       "      <td>4150.427246</td>\n",
       "      <td>4138.974121</td>\n",
       "      <td>4199.487305</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4261.538574</td>\n",
       "      <td>4446.666504</td>\n",
       "      <td>4185.128418</td>\n",
       "      <td>4167.692383</td>\n",
       "      <td>4230.769043</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5114.871582</td>\n",
       "      <td>5250.256348</td>\n",
       "      <td>6214.358887</td>\n",
       "      <td>5431.794922</td>\n",
       "      <td>5228.717773</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            EEG.AF3        EEG.T7        EEG.Pz        EEG.T8       EEG.AF4  \\\n",
       "count  31899.000000  31899.000000  31899.000000  31899.000000  31899.000000   \n",
       "mean    4225.962946   4339.589441   4150.735775   4136.736518   4195.568329   \n",
       "std      115.116010    148.580112    127.110545    126.976150    172.321026   \n",
       "min     3445.128174   2828.718018   2342.564209   3364.102539   1709.230713   \n",
       "25%     4190.256348   4266.153809   4116.410156   4108.205078   4170.256348   \n",
       "50%     4225.641113   4340.000000   4150.427246   4138.974121   4199.487305   \n",
       "75%     4261.538574   4446.666504   4185.128418   4167.692383   4230.769043   \n",
       "max     5114.871582   5250.256348   6214.358887   5431.794922   5228.717773   \n",
       "\n",
       "            emotion  \n",
       "count  31899.000000  \n",
       "mean       3.421424  \n",
       "std        2.454666  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        3.000000  \n",
       "75%        4.000000  \n",
       "max        8.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95955.000000</td>\n",
       "      <td>95955.000000</td>\n",
       "      <td>95955.000000</td>\n",
       "      <td>95955.000000</td>\n",
       "      <td>95955.000000</td>\n",
       "      <td>95955.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4213.073086</td>\n",
       "      <td>4297.634484</td>\n",
       "      <td>4142.020672</td>\n",
       "      <td>4133.424910</td>\n",
       "      <td>4197.101429</td>\n",
       "      <td>3.672284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>241.239572</td>\n",
       "      <td>141.426093</td>\n",
       "      <td>134.925156</td>\n",
       "      <td>140.211141</td>\n",
       "      <td>157.150127</td>\n",
       "      <td>2.911752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1529.743530</td>\n",
       "      <td>2809.743652</td>\n",
       "      <td>2167.179443</td>\n",
       "      <td>2592.307617</td>\n",
       "      <td>1900.512817</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4173.333496</td>\n",
       "      <td>4239.800537</td>\n",
       "      <td>4089.743652</td>\n",
       "      <td>4105.641113</td>\n",
       "      <td>4158.974121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4220.000000</td>\n",
       "      <td>4300.000000</td>\n",
       "      <td>4144.102539</td>\n",
       "      <td>4137.948730</td>\n",
       "      <td>4197.436035</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4264.102539</td>\n",
       "      <td>4361.538574</td>\n",
       "      <td>4195.384766</td>\n",
       "      <td>4168.717773</td>\n",
       "      <td>4235.897461</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8006.666504</td>\n",
       "      <td>5584.615234</td>\n",
       "      <td>6380.000000</td>\n",
       "      <td>6132.820313</td>\n",
       "      <td>6887.692383</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            EEG.AF3        EEG.T7        EEG.Pz        EEG.T8       EEG.AF4  \\\n",
       "count  95955.000000  95955.000000  95955.000000  95955.000000  95955.000000   \n",
       "mean    4213.073086   4297.634484   4142.020672   4133.424910   4197.101429   \n",
       "std      241.239572    141.426093    134.925156    140.211141    157.150127   \n",
       "min     1529.743530   2809.743652   2167.179443   2592.307617   1900.512817   \n",
       "25%     4173.333496   4239.800537   4089.743652   4105.641113   4158.974121   \n",
       "50%     4220.000000   4300.000000   4144.102539   4137.948730   4197.436035   \n",
       "75%     4264.102539   4361.538574   4195.384766   4168.717773   4235.897461   \n",
       "max     8006.666504   5584.615234   6380.000000   6132.820313   6887.692383   \n",
       "\n",
       "            emotion  \n",
       "count  95955.000000  \n",
       "mean       3.672284  \n",
       "std        2.911752  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        3.000000  \n",
       "75%        6.000000  \n",
       "max        8.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_split = np.array(df_train.iloc[:,:-1])\n",
    "y_train_no_split = np.array(df_train.iloc[:,-1])\n",
    "#-----------------------------------------------\n",
    "X_test_original = np.array(df_test.iloc[:,:-1])\n",
    "y_test_original = np.array(df_test.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper-parameter tuning again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"n_estimators\"          : [10,50,75,100,110,120,130,150,200,250,500,750,1000] ,\n",
    " \"criterion\"             : ['gini','entropy'],\n",
    " \"max_leaf_nodes\"        : [ None, 2, 3, 5, 7, 10],\n",
    " \"min_impurity_decrease\" : [0.0,0.05,0.1,0.2,0.3],\n",
    " \"min_samples_split\"     : [0.1,0.5,2,3,4,5,6],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 73.7min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed: 87.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=30, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 50, 75, 100, 110, 120, 130, 150, 200, 250, 500, 750, 1000], 'criterion': ['gini', 'entropy'], 'max_leaf_nodes': [None, 2, 3, 5, 7, 10], 'min_impurity_decrease': [0.0, 0.05, 0.1, 0.2, 0.3], 'min_samples_split': [0.1, 0.5, 2, 3, 4, 5, 6]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=RandomForestClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=30,n_jobs=-1,cv=30,verbose=3)\n",
    "random_search.fit(X_train_no_split,y_train_no_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best parameters :  {'n_estimators': 250, 'min_samples_split': 5, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'criterion': 'gini'}\n",
      "Best Score :  0.5161794591214632\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Estimator : \", random_search.best_estimator_)\n",
    "print(\"Best parameters : \", random_search.best_params_)\n",
    "print(\"Best Score : \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper parameterized conditions after 50 CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_HP = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_HP.fit(X_train_no_split, y_train_no_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17217213, 0.28958433, 0.16645261, 0.20774313, 0.16404781])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_HP.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_HP.predict(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.369353271262422"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_original, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2.5 times better than random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
