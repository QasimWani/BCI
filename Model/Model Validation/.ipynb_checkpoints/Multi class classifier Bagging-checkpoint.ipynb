{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation of Random Forest Bagging classifier with hyper-parameter tuning.\n",
    "### Data : All 7 folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "#------------------\n",
    "from scipy import fft, arange, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_root = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(PATH):\n",
    "    \"\"\"\n",
    "    Finds all the files in a particular directory. Return only .csv files.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for r, d, f in os.walk(PATH):\n",
    "        for file in f:\n",
    "            if '.csv' in file:\n",
    "                files.append(os.path.join(r, file).replace(\"\\\\\",\"/\"))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir_files(root):\n",
    "    \"\"\"\n",
    "    Finds all the files in a nested directory of folders and files (.csv)\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    friendly_name = []\n",
    "    for x in os.listdir(root):\n",
    "        subfolder = root + x\n",
    "        if os.path.isdir(subfolder):\n",
    "            onfo = find_files(subfolder)\n",
    "            if(len(onfo) > 0 and len(x.split(\"_\")) > 1):##Removes test folder and empty folders\n",
    "                files.append(onfo)\n",
    "                fn = x.split(\"/\")[-1]\n",
    "                friendly_name.append(fn)\n",
    "    return files, friendly_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files, friendly_name = list_dir_files(folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meta_data(PATH):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    1. Changes in Electric potential based on Unix timestamp from\n",
    "        the 5 channels of the Emotiv headset. 2 channels from the Frontal Lobe, \n",
    "        1 channel from the parietal lobe, and 2 from temporal lobe.\n",
    "    2. Pandas Dataframe of the data reflected from (1).\n",
    "    \"\"\"\n",
    "    reader = csv.reader(open(PATH, \"rt\"), delimiter='\\t')\n",
    "    i = 0\n",
    "    one_file_data = []\n",
    "    for line in reader:\n",
    "        if(i > 0):\n",
    "            one_file_data.append(line)\n",
    "        i += 1\n",
    "    one_file_data = np.array(one_file_data)\n",
    "    columns = one_file_data[0][0].split(\",\")[3:8]\n",
    "    row_data = []\n",
    "    for rows in one_file_data[1:]:\n",
    "        rd = rows[0].split(\",\")[3:8]\n",
    "        rdt = []\n",
    "        for x in rd:\n",
    "            rdt.append(float(x))\n",
    "        row_data.append(rdt)\n",
    "    dataframe = pd.DataFrame(row_data, columns=columns)\n",
    "    return np.array(row_data), dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_DF_dir(list_PATH):\n",
    "    \"\"\"\n",
    "    Returns all the data from a given set of path files and its associated pandas dataframe object.\n",
    "    \"\"\"\n",
    "    raw_data = []\n",
    "    dataframes = []\n",
    "    for file in list_PATH:\n",
    "        rd, dfob = remove_meta_data(file)\n",
    "        raw_data.append(rd)\n",
    "        dataframes.append(dfob)\n",
    "    return np.array(raw_data), dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_subfolder_file_data(root_list):\n",
    "    \"\"\"\n",
    "    Extracts dataframe and np.array() of each file within each subfolder of the root folder.\n",
    "    Returns:\n",
    "    1. n(n will increase)x5(m varies) dataframe\n",
    "    2. n(n will increase)x5(m varies) np.array()\n",
    "    \"\"\"\n",
    "    root_df = []\n",
    "    root_np = []\n",
    "    for x in root_list:\n",
    "        rnd, rdf = data_DF_dir(x)\n",
    "        root_df.append(rdf)\n",
    "        root_np.append(rnd)\n",
    "    return np.array(root_np), root_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, raw_df = root_subfolder_file_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4216.410156</td>\n",
       "      <td>4259.487305</td>\n",
       "      <td>4187.179688</td>\n",
       "      <td>4088.205078</td>\n",
       "      <td>4203.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4217.948730</td>\n",
       "      <td>4253.846191</td>\n",
       "      <td>4182.051270</td>\n",
       "      <td>4098.974121</td>\n",
       "      <td>4209.230957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4211.794922</td>\n",
       "      <td>4252.307617</td>\n",
       "      <td>4165.128418</td>\n",
       "      <td>4102.051270</td>\n",
       "      <td>4214.871582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4216.410156</td>\n",
       "      <td>4252.820313</td>\n",
       "      <td>4158.974121</td>\n",
       "      <td>4105.128418</td>\n",
       "      <td>4223.077148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4231.794922</td>\n",
       "      <td>4253.333496</td>\n",
       "      <td>4165.641113</td>\n",
       "      <td>4108.717773</td>\n",
       "      <td>4227.692383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EEG.AF3       EEG.T7       EEG.Pz       EEG.T8      EEG.AF4\n",
       "0  4216.410156  4259.487305  4187.179688  4088.205078  4203.589844\n",
       "1  4217.948730  4253.846191  4182.051270  4098.974121  4209.230957\n",
       "2  4211.794922  4252.307617  4165.128418  4102.051270  4214.871582\n",
       "3  4216.410156  4252.820313  4158.974121  4105.128418  4223.077148\n",
       "4  4231.794922  4253.333496  4165.641113  4108.717773  4227.692383"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[0][0].head() ## Anger 0th file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data(dataframe, friendly_name, merge_name):\n",
    "    \"\"\"\n",
    "    Merges all dataframes into one dataframe with associated emotion tag.\n",
    "    \"\"\"\n",
    "    list_df_append_emotion = []\n",
    "    for x,fn in zip(dataframe, friendly_name):\n",
    "        for fil in x:\n",
    "            holder = np.full((1, fil.shape[0]), float(fn.split(\"_\")[0])).T\n",
    "            temp_df = fil\n",
    "            temp_df[merge_name] = holder\n",
    "            list_df_append_emotion.append(temp_df)\n",
    "    pd_df = list_df_append_emotion[0]\n",
    "    for i in range(1, len(list_df_append_emotion)):\n",
    "        pd_df = pd_df.append(list_df_append_emotion[i])\n",
    "    pd_df = pd_df.reset_index().drop(['index'],axis=1)\n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_all_data(raw_df, friendly_name, \"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127854.000000</td>\n",
       "      <td>127854.000000</td>\n",
       "      <td>127854.000000</td>\n",
       "      <td>127854.000000</td>\n",
       "      <td>127854.000000</td>\n",
       "      <td>127854.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4216.289048</td>\n",
       "      <td>4308.102057</td>\n",
       "      <td>4144.195051</td>\n",
       "      <td>4134.251142</td>\n",
       "      <td>4196.718927</td>\n",
       "      <td>3.609695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>216.826926</td>\n",
       "      <td>144.389754</td>\n",
       "      <td>133.071393</td>\n",
       "      <td>137.035810</td>\n",
       "      <td>161.069711</td>\n",
       "      <td>2.806785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1529.743530</td>\n",
       "      <td>2809.743652</td>\n",
       "      <td>2167.179443</td>\n",
       "      <td>2592.307617</td>\n",
       "      <td>1709.230713</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4177.948730</td>\n",
       "      <td>4246.025635</td>\n",
       "      <td>4096.410156</td>\n",
       "      <td>4106.153809</td>\n",
       "      <td>4162.051270</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4221.538574</td>\n",
       "      <td>4308.931397</td>\n",
       "      <td>4146.153809</td>\n",
       "      <td>4137.948730</td>\n",
       "      <td>4197.948730</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4263.077148</td>\n",
       "      <td>4369.743652</td>\n",
       "      <td>4192.820313</td>\n",
       "      <td>4168.205078</td>\n",
       "      <td>4234.358887</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8006.666504</td>\n",
       "      <td>5584.615234</td>\n",
       "      <td>6380.000000</td>\n",
       "      <td>6132.820313</td>\n",
       "      <td>6887.692383</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EEG.AF3         EEG.T7         EEG.Pz         EEG.T8  \\\n",
       "count  127854.000000  127854.000000  127854.000000  127854.000000   \n",
       "mean     4216.289048    4308.102057    4144.195051    4134.251142   \n",
       "std       216.826926     144.389754     133.071393     137.035810   \n",
       "min      1529.743530    2809.743652    2167.179443    2592.307617   \n",
       "25%      4177.948730    4246.025635    4096.410156    4106.153809   \n",
       "50%      4221.538574    4308.931397    4146.153809    4137.948730   \n",
       "75%      4263.077148    4369.743652    4192.820313    4168.205078   \n",
       "max      8006.666504    5584.615234    6380.000000    6132.820313   \n",
       "\n",
       "             EEG.AF4        emotion  \n",
       "count  127854.000000  127854.000000  \n",
       "mean     4196.718927       3.609695  \n",
       "std       161.069711       2.806785  \n",
       "min      1709.230713       0.000000  \n",
       "25%      4162.051270       1.000000  \n",
       "50%      4197.948730       3.000000  \n",
       "75%      4234.358887       6.000000  \n",
       "max      6887.692383       8.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looks good. Data all merged. @ 11:47 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,:-1])\n",
    "y = np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102283, 5), (102283,), (25571, 5), (25571,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape ### Data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "# model2 = svm.SVC()\n",
    "# classifiers.append(model2)\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "model5 = AdaBoostClassifier()\n",
    "classifiers.append(model5)\n",
    "model6 = GradientBoostingClassifier()\n",
    "classifiers.append(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of <class 'xgboost.sklearn.XGBClassifier'> is 0.5880489617144421\n",
      "\n",
      "Confusion Matrix of <class 'xgboost.sklearn.XGBClassifier'> is \n",
      "[[1295 1022  103  512  199  308  592]\n",
      " [ 100 3014    4  122   48  359  329]\n",
      " [ 206  470  526  607   39  102  381]\n",
      " [ 185  694   83 2567   56  159  486]\n",
      " [ 133  118   19  104 1783   43  112]\n",
      " [  27   80    1   31    6 3684   97]\n",
      " [ 209 1345   59  349  220  415 2168]]\n",
      "\n",
      "Accuracy of <class 'sklearn.tree.tree.DecisionTreeClassifier'> is 0.6180829846310273\n",
      "\n",
      "Confusion Matrix of <class 'sklearn.tree.tree.DecisionTreeClassifier'> is \n",
      "[[2245  415  268  345  179  130  449]\n",
      " [ 439 2047  211  341   73  197  668]\n",
      " [ 243  186 1308  250   58   39  247]\n",
      " [ 364  320  305 2727   72   71  371]\n",
      " [ 168   71   49   60 1760   19  185]\n",
      " [ 150  234   42   70   20 3171  239]\n",
      " [ 469  699  269  381  202  198 2547]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qasim\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of <class 'sklearn.ensemble.forest.RandomForestClassifier'> is 0.6996597708341481\n",
      "\n",
      "Confusion Matrix of <class 'sklearn.ensemble.forest.RandomForestClassifier'> is \n",
      "[[2620  462  127  270   96  131  325]\n",
      " [ 366 2713   69  148   41  216  423]\n",
      " [ 221  245 1391  216   30   41  187]\n",
      " [ 320  387  185 2986   36   65  251]\n",
      " [ 150   66   30   57 1900   22   87]\n",
      " [  96  125    9   28    3 3561  104]\n",
      " [ 396  830  141  284  154  240 2720]]\n",
      "\n",
      "Accuracy of <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is 0.48480700793868053\n",
      "\n",
      "Confusion Matrix of <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> is \n",
      "[[ 549 1194  166  677  476  513  456]\n",
      " [  48 2968    2  154   59  367  378]\n",
      " [ 175  562  154  855   88  188  309]\n",
      " [ 281  887  134 1981  189  322  436]\n",
      " [  71  278    7   86 1701   98   71]\n",
      " [   3  156    1   41    6 3676   43]\n",
      " [ 224 1604   65  508  448  548 1368]]\n",
      "\n",
      "Accuracy of <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'> is 0.6071721872433616\n",
      "\n",
      "Confusion Matrix of <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'> is \n",
      "[[1524  884  113  447  177  259  627]\n",
      " [ 125 2971    4   89   50  314  423]\n",
      " [ 236  420  642  519   35   75  404]\n",
      " [ 286  602   99 2571   55  119  498]\n",
      " [ 172   85   23   79 1789   40  124]\n",
      " [  43   91    1   29    6 3646  110]\n",
      " [ 296 1201   81  268  201  335 2383]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of %s is %s\\n\"%(type(clf), acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is \\n%s\\n\"%(type(clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From the results, the highest accuracy score was that of Random Forest Classifier ~67.25%\n",
    "results = model4.predict(X[20000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 result : 312 \n",
      "Class 1 result : 9209\n"
     ]
    }
   ],
   "source": [
    "results = list(results)\n",
    "print(\"Class 0 result : \" + str(results.count(0)), \"\\nClass 1 result : \" + str(results.count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  6.0min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3], 'max_depth': [3, 4, 5, 6, 8, 10, 12, 15], 'min_child_weight': [1, 3, 5, 7], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'colsample_bytree': [0.3, 0.4, 0.5, 0.7]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "classifier=xgboost.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.7, gamma=0.4,\n",
       "       learning_rate=0.15, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 7,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.15,\n",
       " 'gamma': 0.4,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_XGB = xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
    "       min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
    "       nthread=None, objective='multi:softprob', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6826092057408784\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64740336 0.63266901 0.63682565 0.65989054 0.65285379 0.64059445\n",
      " 0.64931507 0.64618395 0.64931507 0.64892368]\n",
      "\n",
      "\n",
      "0.6463974561637347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(best_XGB,X_test,y_test,cv=10)\n",
    "print(score)\n",
    "print(\"\\n\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wow.. After hyper-parameter tuning, xgboost accuracy increased from 56.9% to 67.2%!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation of Random Forest w/ hyper-parameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestVC = RandomForestClassifier(random_state = 1,\n",
    "                                  n_estimators = 10,\n",
    "                                  max_depth = 15, \n",
    "                                  min_samples_split = 5,  min_samples_leaf = 1, criterion='entropy') \n",
    "modelVC = forestVC.fit(X_train, y_train) \n",
    "y_predVC = modelVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6837433029603848"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predVC) #68.09436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"n_estimators\"          : [10,50,100,200,250,500] ,\n",
    " \"criterion\"             : ['gini','entropy'],\n",
    " \"max_leaf_nodes\"        : [ None, 3, 5, 7, 10],\n",
    " \"min_impurity_decrease\" : [0.0,0.05,0.1,0.2],\n",
    " \"min_samples_split\"     : [0.5,2,3,4,5],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 15 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier=RandomForestClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=15,n_jobs=-1,cv=15,verbose=3)\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=4,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred)) ## accuracy increased to 71.3%!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(random_best,X_test,y_test,cv=10)\n",
    "print(score)\n",
    "print(\"\\n\")\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation\n",
    "#get correlations of each features in dataset\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, time to validate with real world test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = find_files(folder_root + \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_df = data_DF_dir(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data structure : 0,1 -> Anger ; 2,3 -> Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(results, friendly_name):\n",
    "    for x in friendly_name:\n",
    "        fn = x.split(\"_\")\n",
    "        print(fn[1] + \" Count : \" + str(test_results.count(int(fn[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = list(random_best.predict(test_data[6]))\n",
    "run_test(test_results, friendly_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fear works...\n",
    "# Reflection... need same video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation of results using keras w/ tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_keras = model.predict(test_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(res_keras, friendly_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reflection : DL activation f(x) sigmoid, relu accuracy 16.61%. epochs set to 150.\n",
    "### Reflection : ML gradient boosting the best algorithm with parameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
